{"chunks": [" \n1\nIITB EdTech Internship 2025, with DYPCET \nTrack 1 - Educational Data Analysis (EDA) \nFinal Problem Statement \n \nT1_G20_4InLine \n \nGroup_ID \nT1_G20 \nGroup_Name \n4InLine \nGroup Leader \nAakash Raju Mohole \nFaculty Mentor \nMrs. Tejashri V Deokar \nDepartment \nData Science \nFinal Problem \nAssigned \nProblem 14. Building a Mental State Monitoring Dashboard \n \nDetailed Final Problem Statement :  \n \nProblem ID - 14. Building a Mental State Monitoring Dashboard \nGoal: Visualize real-time predictions of mental workload, accuracy probability, and emotion transitions. \nGoal: Create a real-time interactive dashboard to visualize: \n\u2022 \nMental workload predictions (e.g., low/medium/high) \n\u2022 \nAccuracy probability (likelihood of correct response) \n\u2022 \nEmotion transitions (e.g., engaged \u2192 confused \u2192 neutral) \n \n \nTools: Streamlit, Dash, Plotly; use pretrained models. \n\u2022 \nFrontend/UI: Streamlit / Dash (Python-based), Plotly for visualization. \n\u2022 \nBackend/Models: Pretrained models for workload, accuracy, and emotion (loaded as .pkl or .pt). \n\u2022 \nData stream: Simulated live data (EEG, GSR, Eye, Facial) \n \nSample Steps for Problem ID - 14. \n \nSTEP 1: Define Inputs & Outputs \n1.1 Inputs \n\u2022 \nSignals: EEG, GSR, Eye-tracking, Facial expression features. \n\u2022 \nModel Outputs: \nworkload_model \u2192 workload level \naccuracy_model \u2192 probability of correct answer \nemotion_model \u2192 current emotion state \n \n1.2 Outputs (dashboard visualizations) \n\u2022 \nGauge/indicator for mental workload \n\u2022 \nLine plot (time-series) of accuracy probability \n\u2022 \nSankey/sequence chart for emotion transitions over time \n\n \n2\n\u2022 \n(Optional) Participant summary panel: latest predictions, confidence scores \n \nSTEP 2: Backend Setup \n2.1 Load Pretrained Models \n\u2022 \nLoad .pkl (sklearn/XGBoost) or .pt (PyTorch/TensorFlow). \nWrap each model in a predictor function: \n \ndef predict_workload(eeg_features): \n    return workload_model.predict([eeg_features])[0] \n \ndef predict_accuracy(multimodal_features): \n    return accuracy_model.predict_proba([multimodal_features])[0,1] \n \ndef predict_emotion(facial_features, eeg_features): \n    return emotion_model.predict([facial_features + eeg_features])[0] \n \n2.2 Simulated \n\u2022 \nSimulated: replay past session CSVs in real-time (e.g., 1 sample/sec). \n \nSTEP 3: Dashboard Design (UI Components) \n3.1 Mental Workload Panel \n\u2022 \nGauge chart (Plotly) with levels (Low/Med/High). \nUpdate every second with the latest prediction. \n \n3.2 Accuracy Probability Panel \n\u2022 \nLine chart showing predicted probability across time. \nAdd threshold line (e.g., 0.5) to visualize confidence. \n \n3.3 Emotion Transitions Panel \n\u2022 \nSankey diagram: flow of emotion states across time blocks. \nAlternative: timeline bar chart where color = emotion. \n \n3.4 Participant Summary Panel \n\u2022 \nLast N seconds snapshot: \nCurrent workload, accuracy, probability, and emotion. \n\u2022 \nConfidence values displayed as percentages. \n \nSTEP 4: Implementation with Streamlit/Dash \n15. Set up environment and dependencies \u2192 Install Streamlit/Dash, P", "lotly, and ML libraries. \n16. Load pretrained models \u2192 Workload, accuracy, and emotion predictors. \n17. Prepare data stream \u2192 Either replay session logs or connect to live sensors. \n18. Design dashboard layout \u2192 Define panels for workload, accuracy probability, and emotion \ntransitions. \n19. Integrate visualizations \u2192 Create gauges, line charts, and emotion flow diagrams. \n20. Enable real-time updates \u2192 Refresh predictions and plots continuously as new data arrives. \n21. Test and refine \u2192 Validate responsiveness, accuracy of model outputs, and usability of the \ninterface. \n\n \n3\n \nSTEP 5: Evaluation & Testing \n\u2022 \nTest with simulated data replay \u2192 check smooth updates. \nStress test with faster refresh rates (100ms, 500ms). \nValidate interpretability: does workload correlate with task difficulty? Does accuracy probability track \nreal outcomes? \n \nSTEP 6: Extensions \n\u2022 \nMulti-user support: dashboard panel per participant. \n\u2022 \nAlert system: if workload too high OR accuracy drops below threshold \u2192 trigger warning. \n\u2022 \nReplay mode: visualize stored session logs as if live. \n\u2022 \nExport: save dashboard outputs as MP4 or session summary CSV. \n \nFile & Code Organization \nproject/ \n\u251c\u2500\u2500 data/ \n\u2502   \u251c\u2500\u2500 EEG.csv \n\u2502   \u251c\u2500\u2500 GSR.csv \n\u2502   \u251c\u2500\u2500 EYE.csv \n\u2502   \u251c\u2500\u2500 TIVA.csv \n\u2502   \u2514\u2500\u2500 session_logs/ \n\u251c\u2500\u2500 models/ \n\u2502   \u251c\u2500\u2500 workload_model.pkl \n\u2502   \u251c\u2500\u2500 accuracy_model.pkl \n\u2502   \u2514\u2500\u2500 emotion_model.pkl \n\u251c\u2500\u2500 app/ \n\u2502   \u251c\u2500\u2500 dashboard.py            # main Streamlit/Dash app \n\u2502   \u251c\u2500\u2500 utils.py                # data stream + feature extraction \n\u2502   \u2514\u2500\u2500 components.py           # plotting helpers \n\u2514\u2500\u2500 README.md \n \n \n\n"], "embeddings": [[3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0, 3000.0], [1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0, 1596.0]]}